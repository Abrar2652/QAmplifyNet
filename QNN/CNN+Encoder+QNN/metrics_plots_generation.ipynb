{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, title=None, cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=[14, 10])\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, fontsize=12)\n",
        "    plt.yticks(tick_marks, classes, fontsize=12)\n",
        "    \n",
        "    if title:\n",
        "        plt.title(title)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, format(cm[i, j], '.2f') + '%',\n",
        "                     ha=\"center\", va=\"center\",\n",
        "                     fontsize=14,\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    #plt.tight_layout()\n",
        "    \n",
        "    plt.xlabel('Predicted label', fontsize=14)\n",
        "    plt.ylabel('True label', fontsize=14)\n",
        "\n"
      ],
      "metadata": {
        "id": "u7KbdgiP6kEJ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2018 Xanadu Quantum Technologies Inc.\n",
        "\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "\"\"\"Script for creating Plots\"\"\"\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#import plot_confusion_matrix\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams.update(mpl.rcParamsDefault)\n",
        "\n",
        "plt.switch_backend('agg')\n",
        "\n",
        "# Label for simulation\n",
        "simulation_label = 1\n",
        "\n",
        "# Loading confusion table\n",
        "confusion_table = np.load('/content/confusion_table.npy')\n",
        "\n",
        "# Defining array of thresholds from 0 to 1 to consider in the ROC curve\n",
        "thresholds_points = 101\n",
        "thresholds = np.linspace(0, 1, num=thresholds_points)\n",
        "\n",
        "# false/true positive/negative rates\n",
        "fp_rate = []\n",
        "tp_rate = []\n",
        "fn_rate = []\n",
        "tn_rate = []\n",
        "\n",
        "# Creating rates\n",
        "for i in range(thresholds_points):\n",
        "    fp_rate.append(confusion_table[i, 0, 1] / (confusion_table[i, 0, 1] + confusion_table[i, 0, 0]))\n",
        "    tp_rate.append(confusion_table[i, 1, 1] / (confusion_table[i, 1, 1] + confusion_table[i, 1, 0]))\n",
        "\n",
        "    fn_rate.append(confusion_table[i, 1, 0] / (confusion_table[i, 1, 1] + confusion_table[i, 1, 0]))\n",
        "    tn_rate.append(confusion_table[i, 0, 0] / (confusion_table[i, 0, 0] + confusion_table[i, 0, 1]))\n",
        "\n",
        "# Distance of each threshold from ideal point at (0, 1)\n",
        "distance_from_ideal = (np.array(tn_rate) - 1)**2 + (np.array(fn_rate) - 0)**2\n",
        "\n",
        "# Threshold closest to (0, 1)\n",
        "closest_threshold = np.argmin(distance_from_ideal)\n",
        "\n",
        "# Area under ROC curve\n",
        "area_under_curve = np.trapz(np.sort(tn_rate), x=np.sort(fn_rate))\n",
        "\n",
        "print(\"Area under ROC curve: \" + str(area_under_curve))\n",
        "print(\"Closest threshold to optimal ROC: \" + str(thresholds[closest_threshold]))\n",
        "\n",
        "# Plotting ROC curve\n",
        "straight_line = np.linspace(0, 1, 1001)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.gcf().subplots_adjust(bottom=0.15)\n",
        "\n",
        "plt.gcf().subplots_adjust(bottom=0.15)\n",
        "plt.plot(fn_rate, tn_rate, label='NN+Encoder+QNN', color='#056eee', linewidth=2.2)\n",
        "plt.plot(straight_line, straight_line, color='#070d0d', linewidth=1.5, dashes=[6, 2])\n",
        "plt.annotate('Minimum ROC Score of 50%\\n(This is the minimum score to get)', xy=(0.7, 0.7), xytext=(0.6, 0.5),\n",
        "            arrowprops=dict(facecolor='#6E726D', shrink=0.05),\n",
        "            )  \n",
        "plt.plot(0.0, 1.0, 'ko')\n",
        "plt.plot(fn_rate[closest_threshold], tn_rate[closest_threshold], 'k^')\n",
        "plt.ylim(-0.05, 1.05)\n",
        "plt.xlim(-0.05, 1.05)\n",
        "plt.grid(True)\n",
        "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
        "plt.title(\"ROC Curve For NN+Encoder+QNN\", fontsize=16)\n",
        "plt.xlabel('False Negative Rate', fontsize=15)\n",
        "plt.ylabel('True Negative Rate', fontsize=15)\n",
        "plt.tick_params(axis='both', which='major', labelsize=12, length=6, width=1)\n",
        "plt.tick_params(axis='both', which='minor', labelsize=12, length=6, width=1)\n",
        "plt.legend(loc='lower right');\n",
        "\n",
        "plt.savefig('./roc.png')\n",
        "plt.show()\n",
        "#plt.close()\n",
        "\n",
        "# Selecting ideal confusion table and plotting\n",
        "confusion_table_ideal = confusion_table[closest_threshold]\n",
        "\n",
        "\n",
        "plot_confusion_matrix(confusion_table_ideal, classes=['No Backorder', 'Backorder'], title='')\n",
        "\n",
        "plt.savefig('./confusion.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w83SQVgNoKlG",
        "outputId": "495b1a3a-8fb3-4e0f-b248-ef43ad5b2a1c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Area under ROC curve: 0.7108582089552239\n",
            "Closest threshold to optimal ROC: 0.54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_table_ideal"
      ],
      "metadata": {
        "id": "Wi9PghhqoKqA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a3a862-5d2f-4551-d72e-a63438a8285b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[59.17602996, 15.73033708],\n",
              "       [ 7.11610487, 17.97752809]])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.metrics import classification_report_imbalanced\n",
        "\n",
        "# Define the confusion matrix in percentage format\n",
        "confusion_matrix_percent = np.array([[59.17602996, 15.73033708],\n",
        "                                     [7.11610487, 17.97752809]])\n",
        "\n",
        "# Define the instance counts\n",
        "instance_counts = np.array([67, 200])\n",
        "\n",
        "# Convert the confusion matrix percentages to counts\n",
        "confusion_matrix_count = np.round(confusion_matrix_percent / 100 * np.sum(instance_counts))\n",
        "confusion_matrix_count"
      ],
      "metadata": {
        "id": "xJIlvGrpoKxU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1999dcb0-700e-4dbe-d635-e133b65331b0"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[158.,  42.],\n",
              "       [ 19.,  48.]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, balanced_accuracy_score, classification_report\n",
        "\n",
        "# Define the confusion matrix\n",
        "confusion_matrix_freq = np.array([[158., 42.],\n",
        "                                 [19., 48.]])\n",
        "\n",
        "# Calculate the metrics\n",
        "true_positive = confusion_matrix_freq[1, 1]\n",
        "false_positive = confusion_matrix_freq[0, 1]\n",
        "false_negative = confusion_matrix_freq[1, 0]\n",
        "true_negative = confusion_matrix_freq[0, 0]\n",
        "\n",
        "precision = true_positive / (true_positive + false_positive)\n",
        "recall = true_positive / (true_positive + false_negative)\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "sensitivity = recall\n",
        "specificity = true_negative / (true_negative + false_positive)\n",
        "accuracy = (true_positive + true_negative) / (true_positive + false_positive + false_negative + true_negative)\n",
        "\n",
        "macro_avg_precision = precision_score([0, 1], [0, 1], average='macro', zero_division=0)\n",
        "macro_avg_recall = recall_score([0, 1], [0, 1], average='macro', zero_division=0)\n",
        "macro_avg_f1 = f1_score([0, 1], [0, 1], average='macro', zero_division=0)\n",
        "\n",
        "weighted_avg_precision = precision_score([0, 1], [0, 1], average='weighted', zero_division=0)\n",
        "weighted_avg_recall = recall_score([0, 1], [0, 1], average='weighted', zero_division=0)\n",
        "weighted_avg_f1 = f1_score([0, 1], [0, 1], average='weighted', zero_division=0)\n",
        "\n",
        "geometric_mean = np.sqrt(sensitivity * specificity)\n",
        "\n",
        "iba = balanced_accuracy_score([0, 1], [0, 1])\n",
        "\n",
        "# Print the metrics with 2 decimal places\n",
        "print(\"Precision: {:.2f}\".format(precision))\n",
        "print(\"Recall: {:.2f}\".format(recall))\n",
        "print(\"F1 Score: {:.2f}\".format(f1))\n",
        "print(\"Sensitivity: {:.2f}\".format(sensitivity))\n",
        "print(\"Specificity: {:.2f}\".format(specificity))\n",
        "print(\"Accuracy: {:.2f}\".format(accuracy))\n",
        "print(\"Macro Average Precision: {:.2f}\".format(macro_avg_precision))\n",
        "print(\"Macro Average Recall: {:.2f}\".format(macro_avg_recall))\n",
        "print(\"Macro Average F1 Score: {:.2f}\".format(macro_avg_f1))\n",
        "print(\"Weighted Average Precision: {:.2f}\".format(weighted_avg_precision))\n",
        "print(\"Weighted Average Recall: {:.2f}\".format(weighted_avg_recall))\n",
        "print(\"Weighted Average F1 Score: {:.2f}\".format(weighted_avg_f1))\n",
        "print(\"Geometric Mean: {:.2f}\".format(geometric_mean))\n",
        "print(\"IBA (Index of Balanced Accuracy): {:.2f}\".format(iba))\n"
      ],
      "metadata": {
        "id": "v0dbzWIjoKz4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddc1d420-10c7-47df-e5e7-8af4ff2b56a2"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.53\n",
            "Recall: 0.72\n",
            "F1 Score: 0.61\n",
            "Sensitivity: 0.72\n",
            "Specificity: 0.79\n",
            "Accuracy: 0.77\n",
            "Macro Average Precision: 1.00\n",
            "Macro Average Recall: 1.00\n",
            "Macro Average F1 Score: 1.00\n",
            "Weighted Average Precision: 1.00\n",
            "Weighted Average Recall: 1.00\n",
            "Weighted Average F1 Score: 1.00\n",
            "Geometric Mean: 0.75\n",
            "IBA (Index of Balanced Accuracy): 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4dD_yre0AWvQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}